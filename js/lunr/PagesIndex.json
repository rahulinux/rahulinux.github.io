[{"title":"about_me","href":"/aboute-me","content":" Just a Simple guy with Linux experience I simply like scriptingcoding and helping others is a fulfilling way to stay up to date and give something back to the community and the web from which I learned so much Currently Working as Big Data DevOps Engineer echo You reach me at tr az nzam ybtvaenuhy90tznvypbz Linkedin2 GitHub3 GooglePlus4 Nixcraft5 1 httpmetastackexchangecomquestions182266howmuchresearcheffortisexpectedofstackoverflowusers182380182380 2 httplinkdin1bjn7dy 3 httpbitly16BcLTv 4 httpbitly1bjnapM 5 httpnixcraftcommembersrahulpatilhtml"},{"title":"SED 10 useful commands","tags":["sed"],"href":"/posts/SED-10-useful-commands","content":"In bash scripting if you want to edit some file from command line then you can use sed 10 Basic examples that Ive provided here youll find using command line more enjoyable and fun About SED sed is an Noninteractive stream editor Features scripting languages work primarily with text file programmable editor accept commandline option and can be scripted sed f scriptname GNU versions supports POSIX Grep and Egrep regexes Does not operate on the source file by default its only print the changes in source file exept i option supports address to indicate to which lines operate on d delete blank lines Usage sed Options instruction file PIPE STDIN Some examples 1 Print line no from file it will print line 1 to 5 sed n 15p filename 2 Print lines except 1 to 6 line shell sed n 16p filename 3 Print below two lines from matches word shell sed ne word2p filename 4 Delete two lines with matches word shell sed e word2d filename 5 Delete below 2 lines from match word shell sed e 5nNd filename 6 search two words shell sed ne monkeydonkeyp filename 7 delete blank file i edit source file and backup sourch file filenamebak shell sed ibak d filename 8 delete second line after first line shell sed ne 12p filename 9 Search and Replace g Global s search I incasecensitive shell sed e sfindreplaceg filename 10 Multiple instruction it will delete blank lines then search RAM and replace SHYAM only print not change in source file shell sed e d e sRAMSHYAMg filename or shell sed e d sRAMSHYAMg filename the line contain NAME in the same line search RAM and replace SHYAM shell sed e NAMEsRAMSHYAMg filename "},{"title":"ansible_basics","href":"/posts/ansible_basics","content":"This Guid will help you to learn Ansible basics and some practical stuff What is Ansible Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy Avoid writing scripts or custom code to deploy and update your applications automate in a language that approaches plain English using SSH with no agents to install on remote systems In Summery Simple IT Automation tool Its Configuration Management tool Provision tool Create New VMAWSInstance Package Installations Deployment Why Ansible YAMAL Based configuration which is easy to read and understand Agentless no need to install any package on remote machine because its uses SSH Batteries included inbuilt modules availablehttpdocsansiblecomansiblemodulesbycategoryhtml Secure its uses SSH protocol Its supports API httpdocsansiblecomansibledevelopingapihtmldetailedapiexample Where we need to Ansible Manage multiple nodes from Single machine Setup Infra like ProdUATDEV in Cloud like AWS Rackspace Google Cloud Integrate with Deployment tools like Jenkins for deploying applications paid versions bamboos Package managment OS Hardening User managment etc Ansible uses Push model we need to push to apply any new changes every single time there is new update to remote machine Terminology Playbook Plain YAML which where you defined list of actiontasks which we are going to performed Tasks Action you are going to perform like package installation or command etc Roles We can create our roles like webserver or database server which include the Playbook Facts There are other places where variables can come from but these are a type of variable that are discovered not set by the user Facts are information derived from speaking with your remote systems Example like get OS name or IP adddress or hostname Templates Its like dynamic file which will store in remote machine with updating variable value templates are processed by the Jinja2 templating language Vars There are 2 types of Variables in Ansible 1 Playbook variable which we defined in Playbook or while running playbook its globally use everywhere in playbook and its also override the other varible which has same name yaml Following way to define variable in playbook vars test abc Inside tasks Runtime variable setfact testabc Or we can specify while running command Runtime variable ansibleplaybook e testabc playbookyaml 2 Defualt variable When we run playbook its try to search variable in some default location which not found in playbook book variable 3 groupvarshostname this is hostbased variable so first ansible will try to search in hostbased variable let say ansible is trying to configure host1 then it will look for groupvarshost1 file for variable 4 groupvarsgroupname this is groupbased variable if variable not found in hostbased variable then it will try search in groupbased 5 groupvarsall at the last its try to search in all which is plain YAML variable file 6 varsfile or you can include your custom variable file Inventory There are two types of inventory in ansible 1 Static Inventory plain text file where your all hosts defined with groups Example Hosts its comments 19216802 ansiblesshuserroot ansiblesshpassredhat var1test 19216803 ansiblesshuserroot ansiblesshpassredhat var1test 192168010 ansiblesshuserroot ansiblesshpassredhat nameblabla Groups its comments webservers 19216801 19216803 dbservers 192168010 To check hosts ansible i invfile all listhost it will return all ips from inventory ansible i invfile webservers listhost it will return all ips from webservers groups To run uptime command on all hosts this is addhoc command ansible i invfile all a uptime 2 Dynamic Invenotory its script which will return the hostsgroups details from any host providers like AWS Docker Rackspace etc Lets do some practical stuff Goal We will install ansible on your local machine and setup following things in remote machine OS Hardening Install base packages Install Ansible on local machine sudo aptaddrepository y ppaansibleansible sudo aptget update sudo aptget install y ansible Create Playbook We will create one common role which will do following things 1 oshardening All things related to OS hardening 2 basepackage Install or compile required packages Also there will be one single file to manage global variables like in future if we need to change version of any application or links etc Now create one dir and cd into it then create yml files mkdir deploynodes ampamp cd deploynodes Create playbook structure mkdir p rolescommontasks touch siteyml touch rolescommontasksmainyml touch rolescommontasksoshardeningyml touch rolescommontasksbasepackagesyml touch groupvarsall So our final structure as below ansiblehosts groupvars all roles common tasks basepackagesyml mainyml oshardeningyml siteyml Now lets configure the oshardeningyml There are many things you can do to secure your OS but for learning ansible we will do basic things like disable root user in ssh and adding MaxAuthTries 3 Lets first defined ssh related variables in varsyml file Edit groupvarsall and configure as below yaml sshdconfig etcsshsshdconfig Note file started with because it YML file so every YML file should have this entry Configure the rolescommontasksoshardeningyml yaml name SSHD Disable Root login lineinfile backupyes statepresent dest sshdconfig regexpPermitRootLogin linePermitRootLogin no name SSHD Updating MaxAuthTries to 3 lineinfile backupyes statepresent dest sshdconfig regexpMaxAuthTries lineMaxAuthTries 3 name SSHD Restarting ssh service service namessh staterestarted Explanation 1 First it will take backup destination file then search line starting with PermitRootLogin and replace with PermitRootLogin no 2 Again search and replace but if search not found then it will add MaxAuthTries 3 3 Finally it will restart ssh to affect the changes Configure rolescommontasksbasepackageyml yaml name Install list of packages action apt updatecacheyes cachevalidtime600 pkgitem stateinstalled withitems unzip buildessential openssl sudo true when ansibledistribution Debian or ansibledistribution Ubuntu Explanation It will first do aptget update if it is not run last 10 min cachevalidtime600 then it will install mention packages Configure rolescommontasksmainyml file yaml include oshardeningyml include basepackagesyml Configure siteyml file yaml hosts all sudo true roles common Add your hosts to ansiblehosts file servers remoteipaddress ansiblesshuserremoteuser ansiblesudopasspassword ansiblesshpasspassword Note if there is any special character in your password then you need to escape it Ex if password is pssw1rd then use pssw1rd Now lets run the ansible command to setup remote host ansibleplaybook vvv i ansiblehosts siteyml If you face ssh fingerprint issue then do following thing and run above command again sudo sed ibkp shostkeychecking Falsehostkeychecking False etcansibleansiblecfg You can find this playbook on github check this page"},{"title":"AWS volume script","tags":["bash","script"],"href":"/posts/aws-volume-script","content":"Here is small useful script which will help you to attach volume on ec2 instances without login into the AWS console Im connected to AWS using VPN so following script will work with private ip but if you are not connected to vpn then you can change PrivateIpAddress to PublicIp binbash set e Create and Attach Volume to Instace using IP Address export AWSACCESSKEYIDXXX export AWSSECRETACCESSKEYXXXXXX export REGIONuseast1 export AWSDEFAULTREGIONREGION if ne 2 then echo Usage 0 exit 1 fi msg echo getinstancedata returns ZONE STATUS IP INSTANCEID DEVICE local host1 if echo host grep qE b2505204090109094b then hostdig short host fi rawdataaws ec2 describeinstances query ReservationsInstancesPlacementAvailabilityZone StateNamePrivateIpAddressInstanceIdBlockDeviceMappingsDeviceName output text grep A1 hostt instancedata echo rawdata head 1 vid echo rawdata grep o sd sort uniq tail 1 cut c 3 tr 09az 19az echo instancedata devsdvid msg Fetching Instance Data read ZONE STATUS IP INSTANCEID DEVICE getinstancedata 1 msg Done msg Creating Volume in Zone ZONE for IP IP ID INSTANCEID volumeidaws ec2 createvolume size 210 region REGION availabilityzone ZONE volumetype standard jq r VolumeId msg Volume has been created with IDvolumeid echo Waiting for Volume availability sleep 30 msg Attaching to Instance aws ec2 attachvolume volumeid volumeid instanceid INSTANCEID device DEVICE Output bash Fetching Instance Data Done Creating Volume in Zone useast1b for IP 1723119121 ID i07208ea25a760e769 Volume has been created with IDvol04b537f936fe0c0e9 Waiting for Volume availability Attaching to Instance AttachTime 20170503T075500921Z InstanceId i07208ea25a760e769 VolumeId vol04b537f936fe0c0e9 State attaching Device devsdd "},{"title":"Getting started with Docker Basics","tags":["docker","containers"],"href":"/posts/getting-started-with-docker","content":" Introduction In this tutorial we will learn following things What is Containers Why Containers Containers vs VMs What is Docker Docker component and architecture Docker Installation Setup on CentOS 7 Docker basic commands In Traditional way of virtualization As we used lot of VMs for dev testing or any R D purpose or may be for different different VMs for applications But actually we create VM then we install OS then we host our application in that OS so its actually takes much resouces in this scenario you will have to give 1G memory for VM OS then for application But if you use containers then you will save resources and you will utilize for proper application use only Take look at following diagram its shows the difference as mention above VMvsContainerhttpwindowsitprocomsitefileswindowsitprocomfilesuploads201501docker20overviewjpg Lets see some basics concept about Containers What is Containers Containers are similar to hardware virtualization like VMs but instead of partitioned the physical machines containers isolate the process in single operating system To do this docker leverages some features in underlying operating system kernel to create multiple isolated userspace process On top of this docker provide features like docker cli Docker also provide imaging system Lets compare the containers with VMs so that you will get more idea Containers Vs Virtual Machines VMs Docker Each VM runs its own Operating system All containers share the same kernel of Host Host OS can be different than guest OS Host OS and container OS has to be same No such concept in VM Containers stop when the command it is started with completes VM take few minutes to boot Containers take few milli seconds to start VM snapshots are hugh in size Images are built incrementally on top of another like layers VMs are not version controlled cant check diff in two VMs Images can be diffed and can be version controlled using Dockerhub like github In normal 4 GB laptop we can run 34 VMs We can run many docker containers You can run only 1 VM using 1 VMDK file Many docker containers can be started from one docker image Why Containers Four key benefits of using containers Portable Image can be ship its mutable image has versions Flexible You can create clean reprodusable and moduler environment Fast Speed at start quickly containers Caching layer of docker make faster build container Efficient we can allocate exactly resource we want like cpumemory it does require full operating system But where this containers fits in usecase hmm to understand this we need to know some concept so lets see that Microservices architecture Previously companies were building one single web application or any application there will be Hugh downtime for any changes because its one single application so now days companies are using microservice approaches because smaller services can handle with separate teams and it can scale and manage individual by team Continaers are natural for microservices Simple to model Dockerfile Any app any languages Image is the version Test deploy same artifact stateless servers decrease change risk Containers Providers Docker We will learn this AWS ECS LXD LXC Docker is supported by almot all the big players in the cloud computing market egAmazon Azure RackSpace etc so we will focus on docker lets start with basics What is Docker Docker is an open platform for developers and sysadmins to build ship and run distributed applications Consisting of Docker Engine a portable lightweight runtime and packaging tool and Docker Hub a cloud service for sharing applications and automating workflows Docker enables apps to be quickly assembled from components and eliminates the friction between development QA and production environments As a result IT can ship faster and run the same app unchanged on laptops data center VMs and any cloud Docker Architecture Docker uses a clientserver architecture The Docker client talks to the Docker daemon which does the heavy lifting of building running and distributing your Docker containers The Docker client and daemon can run on the same system or you can connect a Docker client to a remote Docker daemon The Docker client and daemon communicate using a REST API over UNIX sockets or a network interface DockerArchhttpsdocsdockercomenginearticleimgarchitecturesvg Docker daemon Engine The Docker daemon runs on a host machine The user uses the Docker client to interact with the daemon The Docker engine is the actual middleware that runs monitors orchestrate the containers Docker client in the form of the docker binary is the primary user interface to Docker It accepts commands and configuration flags from the user and communicates with a Docker daemon One client can even communicate with multiple unrelated daemons Docker Image A Docker image is a readonly template with instructions for creating a Docker container For example an image might contain an Ubuntu operating system with Apache web server and your web application installed You can build or update images from scratch or download and use images created by others An image may be based on or may extend one or more other images A docker image is described in text file called a Dockerfile which has a simple welldefined syntax Docker containers A Docker container is a runnable instance of a Docker image You can run start stop move or delete a container using Docker API or CLI commands When you run a container you can provide configuration metadata such as networking information or environment variables Each container is an isolated and secure application platform but can be given access to resources running in a different host or container as well as persistent storage or databases Docker registries A docker registry is a library of images A registry can be public or private and can be on the same server as the Docker daemon or Docker client or on a totally separate server take look at public registry Docker hub at httpshubdockercomexplore Docker filesystem Docker uses Union File System with Storage driver AUFS for Ubuntu and driver devicemapper for RHELCentOS UnionFS used because its Avoid duplicating a complete set of files each time you run an image as a new container its isolate changes to a container filesystem in its own layer allowing for that same container to be restarted from a known content since the layer with the changes will have been dismissed when the container is removed Read more about filesystem and How does docker image workhttpsdocsdockercomengineunderstandingdockerhowdoesadockerimagework Installation Prerequisites Docker must be installed on 64 bit OS with kernel more than 310 The kernel must support an appropriate storage driver Installation on CentOS 7 1 Add Official docker repo shell cat etcyumreposddockerrepo Docker nameDocker Repository baseurlhttpsyumdockerprojectorgrepomaincentos7 enabled1 gpgcheck1 gpgkeyhttpsyumdockerprojectorggpg EOF 2 Install dockerengine shell yum install y dockerengine Note if docker is already install make sure to remove older version using yum remove docker containerselinux dockercommon dockerclient 3 Start service and add in startup shell systemctl restart dockerservice chkconfig level 35 docker on check docker info using docker info 4 Testing Docker shell docker run helloworld Output will be like shell Unable to find image helloworldlatest locally latest Pulling from libraryhelloworld 78445dd45222 Pull complete Digest sha256c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7 Status Downloaded newer image for helloworldlatest Hello from Docker This message shows that your installation appears to be working correctly To generate this message Docker took the following steps 1 The Docker client contacted the Docker daemon 2 The Docker daemon pulled the helloworld image from the Docker Hub 3 The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading 4 The Docker daemon streamed that output to the Docker client which sent it to your terminal To try something more ambitious you can run an Ubuntu container with docker run it ubuntu bash Share images automate workflows and more with a free Docker ID httpsclouddockercom For more examples and ideas visit httpsdocsdockercomengineuserguide In Next tutorial we will see some usefull handson on docker Feel free to comment or email if you have any questionsuggessions"},{"title":"Hands on docker commands","tags":["docker","docker-cli","containers"],"href":"/posts/hands-on-docker-commands","content":" Introduction In the previous tutorial we have learn about docker and containers and Installation of docker now we will see how to play with container because handling containers is the sole purpose of all these infrastructure 1 RUN command shell docker run helloworld Whats just happend Basically once you run above command its do following things Check helloworld image is exists or not locally thats why you see first msg Unable to find in first ran Pullimage from docker hub if not exists in local Create container from downloaded image with some random name Start the container in forground mode all output on TTY from downloaded image Once process is finished then it will stop the container in our case it was just print helloworld message If you want to run container in background then you can simply pass d flag to run command as below shell docker run d centos binbash It will run container in detached mode Another command for interactive mode shell docker run i t centos binbash Run command has many option you can check man dockerrun for more info some basic overview as below The run options control the images runtime behavior in a container These settings affect detached or foreground running container identification and name network settings and host name runtime constraints on CPU and memory privileges and LXC configuration 2 Create command Create command only create container with settings you provided it does not start container Example To create shell docker create name testcn i t centos binbash Output shell d63f927cf1c9cc7899389dfddb52fd104b4f2ed7a211e11cf994ea7a644fdd7d The output you see its a container ID every container has uniq id we have provided name testcn to container if you do not provided name then you can use container id which is output of above command To start shell docker start a i testcn OR shell docker start a i d63f927cf1c 3 Start Stop and Restart command To change the container state you can use thise command like our init script When you fire stop command docker actually sends signal 15 SIGTERM to the process The SIGTERM signal requests the process to terminate itself gracefully once signal sends docker will wait for some timeout if its does not stop then after timeout docker will send SIGTERM signal 9 to kill the process forcefully Usage docker stop start restart OPTIONS CONTAINER CONTAINER Options t time10 Seconds to wait for stop before killing it Container Control the container either by Name or ID 4 Exec command Now let say you have runing container and you want to run some commands in runing container in this case you can use exec command shell docker exec t testcn bash c cat etchosts shell docker exec it testcn bash This will create new bash session in the running container 5 cp command Copy data fromto running container Example shell docker cp testcnetchosts testcnhostsfile This will copy hosts file from testcn container to local path with name testcnhostsfile Usage shell docker cp OPTIONS CONTAINERPATH LOCALPATH docker cp OPTIONS LOCALPATH CONTAINERPATH 6 attach command This commands brings a container to the foreground The container must be running to be attached Usage shell docker attach OPTIONS CONTAINER Example shell docker attach testcn Once you run exit command or after attaching container you kill process inside container it will go to stop mode 7 Inspect command It will gives you all container system information like networkosdriver etc in json format Example shell docker inspect testcn 8 rm command This command is used to delete any container either by name or ID Put Make sure that the container is stopped before you remove it shell docker rm CONTAINERID 9 ps command Shows the current running containers on the system and with a flag list all containers that has been created To check running containers shell docker ps for checking all containers shell docker ps a 10 Search and pull image If you want to search any ready image let say for java then you can simply use search and pull To search all java images shell docker search java To pull on java image shell docker pull java 11 Docker save and load image and list images Lets say you have created your custom image now you want to export in file and copy to another server then you can simply use this option its just for portable version of docker images Usage shell docker save o testcntar testcn docker load input testcn To list downloaded images shell docker images Mix command To stop all container in one single command shell docker stop docker ps aq I hope this is useful for you feel free to emailcomment if any quires In next tutorial we will learn about building docker images"},{"title":"Useful Linux Commands","tags":["linux","Tips"],"href":"/posts/hands-on-linux-commands","content":"In this post I want to list some useful shell scriptscommands keyboard shortcuts some may be already known to you and some may not be but nonetheless I feel its my duty to share some not so trivial things to search and find that easily sometimes also I needed a quick reference of these which may be useful for Linux System Admin coders including me in future so here we go 1 Place the argument of the most recent command on the shell When typing out long arguments such as shell tail f varlogmessages You can put that argument on your command line by holding down the ALT key and pressing the period or by pressing ESC then the period For example tail f ALT this would put varlogmessages as my argument Keeping pressing ALT to cycle through arguments of your commands starting from most recent to oldest This can save a ton of typing In Mac you can use ESC 2 Man Pages Command man is your friend Before googling you should check man pages to solve issue yourself here is simple Example if want to understand File System Hierarchy then simply use shell man hier 3 SSH If ServerB is Not accessible but you can access ServerA and ServerA can access ServerB then you can use shell ssh t ServerA ssh ServerB Directly ssh to ServerB that is only accessible through ServerA 4 RPM DPKG If you want to Check which file belongs to which package In RHELCentOS shell rpm qf pathoffile In Ubuntu shell dpkg S pathoffile Note that if package installed using source code then it will never show only apply for files those are installed through package manager 5 Get absolute Path of file This trick very useful in Shell Script if you want to check absolute path of file which is in your current directory shell readlink f filename If you want to get absolute path of script it self shell ThisScriptreadlink f 0 6 BackupRename File If you want to Backup file with current date name shell cp filenamebkpdate F If you want to rename file shell mv filenameold 7 Fast builtin pipebased data sink shell Yourcommand This is shorter and actually much faster than devnull see sample output for timings 8 Save Command in History Without Executing it Type your command and Simple Press ALT 9 Search and Execute Recent commands from your history Simply Press Ctrlr and type some word to search your Command Simply do Next using Ctrlr to cycle through commands 10 Fast Execute recent command Suppose you have Open file using vim then you save file and run some other command now just run shell vim this will execute last command start with vim from your history If you want to share any command line tips tricks just post in comments"},{"title":"Kubernetes Basics","tags":["docker","containers","kubernetes","microservice"],"href":"/posts/kubernetes-basics","content":" Introduction This guide will help to understand basics concepts of Kubernetes What is Kubernets Kubernetes commonly referred to as k8s is an open source container cluster manager originally designed by Google and donated to the Cloud Native Computing Foundation It aims to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts It usually works with the Docker container tool and coordinates between a wide cluster of hosts running Docker With Kubernetes you are able to quickly and efficiently respond to customer demand Deploy your applications quickly and predictably Scale your applications on the fly Seamlessly roll out new features Optimize use of your hardware by using only the resources you need Kubernetes is portable public private hybrid multicloud extensible modular pluggable hookable composable selfhealing autoplacement autorestart autoreplication autoscaling READ ABOUT CONTAINERShttpsaucourantoncom20140613linuxcontainersparallelslxcopenvzdockerandmore Kubernetes Concepts Cluster A cluster is a set of physical or virtual machines and other infrastructure resources used by Kubernetes to run your applications Node A node is a physical or virtual machine running Kubernetes onto which pods can be scheduled Pod A pod is a colocated group of containers and volumes Kubernetes targets the management of elastic applications that consist of multiple microservices communicating with each other Often those microservices are tightly coupled forming a group of containers that would typically in a noncontainerized setup run together on one server This group the smallest unit that can be scheduled to be deployed through K8s is called a pod This group of containers would share storage Linux namespaces cgroups IP addresses These are colocated hence share resources and are always scheduled together Pods are not intended to live long They are created destroyed and recreated on demand based on the state of the server and the service itself Label A label is a keyvalue pair that is attached to a resource such as a pod to convey a userdefined identifying attribute Labels can be used to organize and to select subsets of resources Selector A selector is an expression that matches labels in order to identify related resources such as which pods are targeted by a loadbalanced service Replication Controller A replication controller ensures that a specified number of pod replicas are running at any one time It both allows for easy scaling of replicated systems and handles recreation of a pod when the machine it is on reboots or otherwise fails Service As pods have short lifetime there is not guarantee about the IP address they are served on This could make the communication of microservices hard Imagine a typical Frontend communication with Backend services Hence K8s has introduced the concept of service which is an abstraction on top of number of pods typically requiring to run a proxy on top for other services to communicate with it via a Virtual IP address This is where you can configure load balancing for your numerous pods and expose them via a service Volume A volume is a directory possibly with some data in it which is accessible to a Container as part of its filesystem Kubernetes volumes build upon Docker Volumes adding provisioning of the volume directory andor device Secret A secret stores sensitive data such as authentication tokens which can be made available to containers upon request Name A user or clientprovided name for a resource Namespace A namespace is like a prefix to the name of a resource Namespaces help different projects teams or customers to share a cluster such as by preventing name collisions between unrelated teams Annotation A keyvalue pair that can hold larger compared to a label and possibly not humanreadable data intended to store nonidentifying auxiliary data especially data manipulated by tools and system extensions Efficient filtering by annotation values is not supported Networking flannel is a virtual network that gives a subnet to each host for use with container runtimes read more about this on httpsgithubcomcoreosflannel Component Master Node Master node is responsible for the management of Kubernetes cluster This is the entry point of all administrative tasks Master node is the one taking care of orchestrating the worker nodes where the actual services are running Inside Master Node API server API server is the entry points for all the REST commands used to control the cluster It processes the rest requests validates them executes the bound business logic The result state has to be persisted somewhere and that brings us to the next component of the master node etcd storage etcd is a simple distributed consistent keyvalue store Its mainly used for shared configuration and service discovery It provides a REST API for CRUD operations as well as an interface to register watchers on specific nodes which enables a reliable way to notify the rest of the cluster about configuration changes Example of data stored by Kubernetes in etcd are jobs being scheduled created and deployed podservice details and state namespaces and replication informations etc scheduler The deployment of configured pods and services onto the nodes happens thanks to the scheduler component Scheduler has the information regarding resources available on the members of the cluster as well as the ones required for the configured service to run and hence is able to decide where to deploy a specific service controllermanager Optionally you can run different kinds of controllers inside the master node controllermanager is a daemon embedding those A controller uses apiserver to watch the shared state of the cluster and makes corrective changes to the current state to being it to the desired one An example of such a controller is the Replication controller which takes care of the number of pods in the system The replication factor is configured by the user and thats the controllers responsibility to recreate a failed pod or remove an extrascheduled one Other examples of controllers are endpoints controller namespace controller and serviceaccounts controller Flannel A network overlay that will allow containers to communicate across multiple hosts Worker node The pods are run here so the worker node contains all the necessary services to manage the networking between the containers communicate with the master node and assign resources to the containers scheduled Inside Worker node Docker Docker runs on each of the worker nodes and runs the configured pods It takes care of downloading the images and starting the containers kublet kubelet gets the configuration of a pod from the apiserver and ensures that the described containers are up and running This is the worker service thats responsible for communicating with master ndoe It also communicates with etcd to get information about services and write the details about newly created ones kubeproxy kubeproxy acts as a network proxy and a load balancer for a service on a single worker node It takes care of the network routing for TCP and UDP packets kubectl And final bit a command line tool to communicate with API service and send commands to the master node Flannel A network overlay that will allow containers to communicate across multiple hosts Architecturehttpss3uswest2amazonawscomxteamghostimages201606o7leokpng This is obviously a very simplistic description If you wish to dig deeper just read the official documentation on httpkubernetesio"},{"title":"Setup Kubernetes Cluster","tags":["docker","containers","kubernetes","microservice"],"href":"/posts/kubernetes-installation","content":" Introduction In the previous post we have learn kubernetes basics and understand its components now in this tutorial we will see how to setup 3 nodes kubernets cluster There is lots of tools available to setup kubernetes like Minikube kubeadm and Kargo I found very simple installation using Kargo now knows as Kubespray which is just ansible playbooks So we can see how to setup 3 node kubernetes cluster using Kargo Assuming that you have ready installed 3 nodes of CentOS 74 or higher you can have it on Pysical server or VM or AWS or any cloud you just need to have ssh access to this servers Perquisite yum install pythonpip git pythonnetaddr pip install ansible230 Download the Kargo git clone httpsgithubcomkubernetesincubatorkubespray Configuring the static inventory file cd kubespray cp inventoryinventoryexample inventoryinventory vim inventoryinventory Configure ip variable to bind kubernetes services on a different ip than the default iface node1 ansiblesshhostmyhost01 ip1111 node2 ansiblesshhostmyhost02 ip1112 node3 ansiblesshhostmyhost03 ip1113 configure a bastion host if your nodes are not directly reachable bastion ansiblesshhostxxxx kubemaster node1 node2 etcd node1 node2 node3 kubenode node1 node2 node3 k8sclusterchildren kubenode kubemaster Test connection ansible i inventoryinventory all m shell a uptime Configure variables vim inventorygroupvarsk8sclusteryml kubeapipwd changepassword Installing Kubernetes ansibleplaybook i inventoryinventory clusteryml vv In case if you face any issue you can run resetyml playbook Once installation is finished you can login to any node and check the status using following command kubectl get nodes"},{"title":"Send password expiry notification to nix users using Python script","tags":["scripting","python"],"href":"/posts/python-script-display-and-mail-users-account-expiry-details","content":"Are you Managing N Number of Users and want to check Account Expires and send notification to administrator through Gmail Here is a Python script which will send notification to administrator which accounts are going to expire in 7 days You are free to use and modify this script for your work python usrbinenv python Name checkUsrAccountExpirypy v 01 Copyleft c Pupose To check the user account expire status in Linux unix BSD etc Author Rahul Patil Created 12 Jun 2013 Version 01 License free Report checkUsrAccountExpirypy bugs to loginrahul90gmailcom import re import socket import smtplib import datetime Specify Mail Login Credencial hostname socketgethostname sender yourmailidgmailcom password yourpassword recipient loginrahul90gmailcom set admin email ID subject Account Expiry Details of rformathostname mindays 20 set min days Specify SMTP Server server smtpgmailcom port 587 body1 8s 2n days Last date 3s body2 8s Expired on 3s msg Sent Mail def mailItbody body rnjoinbody headers From sender Subject subject To recipient MIMEVersion 10 ContentType texthtml headers rnjoinheaders session smtplibSMTPserver port sessionehlo sessionstarttls sessionehlo sessionloginsender password print nnSending Mail sessionsendmailsender recipient headers rnrn body print Sent Successfullly sessionquit totalexpiredusers 0 totalexpringusers 0 exprlist Convert Unix timestamp to Readable Datetime def convUnixTimet return datetimedatetimefromtimestampt606024 Read shadow file and check for account expriry with open etcshadow as shadow for aLine in shadow filed aLinesplit Ac filed7 try Ac intAc exprdate convUnixTimeAc Ac1 exprdate datetimedatetimetodaydays lAcexprdate except ValueError pass else if Ac mindays exprlistfiled0l if Ac Following r Account has been Expiredformatt1 index t1 else index 1 for usrdays in exprlistiteritems dtstrdays1 if days0 0 msginsert1body2formatusrdt elif days0 Following 0 Account will be Expire in 1 Daysformatt2mindays return msg msg AccountExprDetails if name main if lenmsg print njoinmsg mailItmsg else print No User Account has been Expire Sample Output Following 3 Account has been Expired test Expired on 20130601 053000 vinayak Expired on 19700101 053000 ram Expired on 20130614 053000 Following 4 Account will be Expire in 20 Days suraj 1 days Last date 20130615 053000 javed 1 days Last date 20130615 053000 shyam 1 days Last date 20130615 053000 Sending Mail Sent Successfully You can find Updated Script from thishttpsgithubcomrahulinuxcheckUsrAccountExpirypyblobmastercheckUsrAccountExpirypy page Have fun "},{"title":"Setup Private Docker Registry","tags":["docker","docker-cli","containers","docker-registry"],"href":"/posts/setup-private-docker-registry","content":" Introduction In this tutorial we are going to learn about Docker registry and how to setup your own private registry with selfsign certificates I hope you have read previous posts on docker basics and its concepts What is Docker Registry A registry is a storage and content delivery system holding named Docker images available in different tagged versions There are to types of Registry Public Registry The default registry for all images Docker hubhttpshubdockercom which provides a freetouse hosted Registry plus additional features organization accounts automated builds and more Private Registry In case if you dont want to publish your own images to outside world or to improve the download speed instead of downloading images docker hub we can make the private registry and its a great solution to integrate with and complement your CICD system Example like Nexushttpswwwsonatypecomdocker or Docker registryhttpsdocsdockercomregistry or Portushttpportusorg How its works When you run docker run it centos bash or docker pull centos command its first checks the image exists locally or not if not then it pulls from the Docker hubhttpshubdockercom imagine if you are pulling image on multiple servers you will have to download the image from docker hub multiple times this process will take huge time if your internet connection is slow So to avoid this we can build our private repository where we can store our private images that is use case one but other use like you tightly control where your images are being stored fully own your images distribution pipeline Setup Private Registry There are two ways of setting up your private registry 1 Using selfsign certificates Quick and dirty way 2 Register Certificates for your domain For production setup Method 1 Lets try with selfsign certificates 1 Create directory for hosting registry and registry storage bash mkdir optdockerregistry cd optdockerregistry mkdir data mkdir certs 2 Generate selfsign certificates bash openssl req newkey rsa4096 nodes sha256 keyout certsdomainkey x509 days 365 out certsdomaincrt 3 Start your registry bash docker run d p 50005000 restartalways name registry v PWDdatavarlibregistry v PWDcertscerts e REGISTRYHTTPTLSCERTIFICATEcertsdomaincrt e REGISTRYHTTPTLSKEYcertsdomainkey registry2 Testing We can test from same host but since we are using selfsign certificates we need to install in docker client for that you need to copy certificate file in etcdockerconfd5000cacrt lets assume that your FQDN is registrylinuxiancom Instaling Linux client certificates mkdir etcdockercertsdregistrylinuxiancom5000 cp certsdomaincrt etcdockercertsdregistrylinuxiancom5000cacrt Now try to push any local image to your registry server docker images Copy any image id from about command output docker tag registrylinuxiancom5000testimage docker push registrylinuxiancom5000testimage Bingo Congrantulation you just setup your private registry Instaling Mac OS client certificates mkdir etcdockercertsdregistrylinuxiancom5000 cp domaincrt etcdockercertsdregistrylinuxiancom5000cacrt sudo security addtrustedcert d r trustRoot k LibraryKeychainsSystemkeychain etcdockercertsdregistrylinuxiancom5000cacrt Now you can pushpull from your registry server Method 2 Following things require to run in production Registered Domain SSL certificates As you can see in above picture you can use Load Balanacer like HAproxy Nginx or ELB in AWS which handle SSL and proxy request to your registry server"}]